{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import diag\n",
    "import scipy\n",
    "import os\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import paddle\n",
    "from paddle import fluid\n",
    "from paddle_quantum.circuit import UAnsatz\n",
    "from paddle.complex import matmul, trace, kron\n",
    "from paddle_quantum.utils import dagger, state_fidelity, partial_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_file = np.load(os.path.join(root, '../datasets/breastmnist.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = npz_file['train_images']\n",
    "train_images = train_images.reshape(train_images.shape[0], -1)\n",
    "pca = PCA(n_components=8)\n",
    "new_train = pca.fit_transform(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_train)):\n",
    "    new_train[i] = new_train[i] / new_train[i].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_A = 2        # 系统 A 的量子比特数\n",
    "N_B = 1        # 系统 B 的量子比特数\n",
    "N = N_A + N_B  # 总的量子比特数\n",
    "\n",
    "scipy.random.seed(1)                            # 固定随机种子\n",
    "V = scipy.stats.unitary_group.rvs(2**N)         # 随机生成一个酉矩阵\n",
    "   # 输入目标态rho的谱\n",
    "V_H = V.conj().T                                # 进行厄尔米特转置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置电路参数\n",
    "cir_depth = 6                        # 电路深度\n",
    "block_len = 2                        # 每个模组的长度\n",
    "theta_size = N*block_len*cir_depth   # 网络参数 theta 的大小\n",
    "\n",
    "\n",
    "# 搭建编码器 Encoder E\n",
    "def Encoder(theta):\n",
    "\n",
    "    # 用 UAnsatz 初始化网络\n",
    "    cir = UAnsatz(N)\n",
    "    \n",
    "    # 搭建层级结构：\n",
    "    for layer_num in range(cir_depth):\n",
    "        \n",
    "        for which_qubit in range(N):\n",
    "            cir.ry(theta[block_len*layer_num*N + which_qubit], which_qubit)\n",
    "            cir.rz(theta[(block_len*layer_num + 1)*N + which_qubit], which_qubit)\n",
    "\n",
    "        for which_qubit in range(N-1):\n",
    "            cir.cnot([which_qubit, which_qubit + 1])\n",
    "        cir.cnot([N-1, 0])\n",
    "\n",
    "    return cir.U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize2unitary(x):\n",
    "    rho_in_mols=x\n",
    "    rho_in_mols=(V@diag(rho_in_mols)@V_H).astype('complex128')\n",
    "    return rho_in_mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_C = np.diag([1,0]).astype('complex128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_A = 2        # 系统 A 的量子比特数\n",
    "N_B = 1        # 系统 B 的量子比特数\n",
    "N = N_A + N_B  # 总的量子比特数\n",
    "LR = 0.2       # 设置学习速率\n",
    "ITR = 100      # 设置迭代次数\n",
    "SEED = 14      # 固定初始化参数用的随机数种子\n",
    "\n",
    "class NET4(fluid.dygraph.Layer):\n",
    "    \"\"\"\n",
    "    Construct the model net\n",
    "    \"\"\"\n",
    "    def __init__(self, shape, param_attr=fluid.initializer.Uniform(\n",
    "        low=0.0, high=2 * np.pi, seed = SEED), dtype='float64'):\n",
    "        super(NET4, self).__init__()\n",
    "        \n",
    "        # 我们需要将 Numpy array 转换成 Paddle 动态图模式中支持的 variable\n",
    "        self.rho_C = fluid.dygraph.to_variable(rho_C)\n",
    "        self.theta = self.create_parameter(shape=shape, \n",
    "                     attr=param_attr, dtype=dtype, is_bias=False)\n",
    "    \n",
    "    # 定义损失函数和前向传播机制\n",
    "    def forward(self,x):\n",
    "        # 生成初始的编码器 E 和解码器 D\\n\",\n",
    "        rho_in= fluid.dygraph.to_variable(x)\n",
    "        E = Encoder(self.theta)\n",
    "        E_dagger = dagger(E)\n",
    "        D = E_dagger\n",
    "        D_dagger = E\n",
    "\n",
    "        # 编码量子态 rho_in\n",
    "        rho_BA = matmul(matmul(E, rho_in), E_dagger)\n",
    "        \n",
    "        # 取 partial_trace() 获得 rho_encode 与 rho_trash\n",
    "        rho_encode = partial_trace(rho_BA, 2 ** N_B, 2 ** N_A, 1)\n",
    "        rho_trash = partial_trace(rho_BA, 2 ** N_B, 2 ** N_A, 2)\n",
    "\n",
    "        # 解码得到量子态 rho_out\n",
    "        rho_CA = kron(self.rho_C, rho_encode)\n",
    "        rho_out = matmul(matmul(D, rho_CA), D_dagger)\n",
    "        \n",
    "        # 通过 rho_trash 计算损失函数\n",
    "        \n",
    "        zero_Hamiltonian = fluid.dygraph.to_variable(np.diag([1,0]).astype('complex128'))\n",
    "        loss = 1 - (trace(matmul(zero_Hamiltonian, rho_trash))).real\n",
    "\n",
    "        return loss, rho_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx=new_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.87120932, -0.49674465,  0.49908907,  0.39252061, -0.30385798,\n",
       "        0.10832221, -0.05726161, -0.01327696])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(normalize2unitary(xxx)).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 8]\n"
     ]
    }
   ],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    net=NET4([theta_size])\n",
    "    xxx2=normalize2unitary(xxx)\n",
    "    l, a=net(xxx2)\n",
    "    \n",
    "    print(a.shape)\n",
    "    #print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 100 loss: -0.8674 fid: 1.7559\n",
      "iter: 200 loss: -0.8686 fid: 1.6087\n",
      "iter: 300 loss: -0.8697 fid: 1.5071\n",
      "iter: 400 loss: -0.8700 fid: 1.4664\n",
      "iter: 500 loss: -0.8701 fid: 1.4793\n",
      "iter: 600 loss: -0.8702 fid: 1.5143\n",
      "iter: 700 loss: -0.8703 fid: 1.5538\n",
      "iter: 800 loss: -0.8705 fid: 1.5929\n",
      "iter: 900 loss: -0.8706 fid: 1.6288\n",
      "iter: 1000 loss: -0.8706 fid: 1.6590\n"
     ]
    }
   ],
   "source": [
    "step=1\n",
    "with fluid.dygraph.guard():\n",
    "    net = NET4([theta_size])\n",
    "    \n",
    "    opt = fluid.optimizer.AdagradOptimizer(learning_rate=LR, \n",
    "                          parameter_list=net.parameters())\n",
    "    \n",
    "    x=new_train[1]\n",
    "        \n",
    "    trainx=normalize2unitary(x)\n",
    "       \n",
    "    for i in range(1000):\n",
    "        step=step+1\n",
    "        #x=new_train2[0]\n",
    "        \n",
    "        #trainx=normalize2unitary(x)\n",
    "       \n",
    "        loss, rho_out = net(trainx)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.minimize(loss)\n",
    "        net.clear_gradients()\n",
    "        fid = state_fidelity(trainx, rho_out.numpy())\n",
    "        if (step) % 100 ==0:\n",
    "            print('iter:', step, 'loss:', '%.4f' % loss, 'fid:', '%.4f' % np.square(fid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
