{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入相应的库\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import copy\n",
    "import pdb\n",
    "\n",
    "from collections import OrderedDict\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import diag\n",
    "from paddle import fluid\n",
    "from paddle.complex import kron, matmul, trace\n",
    "from paddle_quantum.circuit import UAnsatz\n",
    "from paddle_quantum.utils import dagger, partial_trace, state_fidelity\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from numpy import pi as PI\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from paddle import fluid\n",
    "from paddle.fluid.framework import ComplexVariable\n",
    "from paddle.complex import matmul, transpose\n",
    "from paddle_quantum.circuit import UAnsatz\n",
    "from paddle_quantum.utils import pauli_str_to_matrix"
   ]
  },
  {
   "source": [
    "数据集\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_file = np.load('../datasets/minidata.npz')\n",
    "train_images = npz_file['train_images']\n",
    "train_images = train_images.reshape(train_images.shape[0], -1)\n",
    "\n",
    "val_images = npz_file['val_images']\n",
    "val_images = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "pca = PCA(n_components=8)\n",
    "new_train = pca.fit_transform(train_images)\n",
    "new_val = pca.fit_transform(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保证每张图片的向量所有元素之和为1\n",
    "for i in range(len(new_train)):\n",
    "    new_train[i] = new_train[i] / new_train[i].sum()\n",
    "    \n",
    "for i in range(len(new_val)):\n",
    "    new_val[i] = new_val[i] / new_val[i].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "电路设置\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_A = 2        # 系统 A 的量子比特数\n",
    "N_B = 1        # 系统 B 的量子比特数\n",
    "N = N_A + N_B  # 总的量子比特数\n",
    "\n",
    "scipy.random.seed(1)                            # 固定随机种子\n",
    "V = scipy.stats.unitary_group.rvs(2**N)         # 随机生成一个酉矩阵\n",
    "V_H = V.conj().T                                # 进行厄尔米特转置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置电路参数\n",
    "cir_depth = 6                        # 电路深度\n",
    "block_len = 2                        # 每个模组的长度\n",
    "theta_size = N*block_len*cir_depth   # 网络参数 theta 的大小\n",
    "\n",
    "\n",
    "# 搭建编码器 Encoder E\n",
    "def Encoder(theta):\n",
    "\n",
    "    # 用 UAnsatz 初始化网络\n",
    "    cir = UAnsatz(N)\n",
    "    \n",
    "    # 搭建层级结构：\n",
    "    for layer_num in range(cir_depth):\n",
    "        \n",
    "        for which_qubit in range(N):\n",
    "            cir.ry(theta[block_len*layer_num*N + which_qubit], which_qubit)\n",
    "            cir.rz(theta[(block_len*layer_num + 1)*N + which_qubit], which_qubit)\n",
    "\n",
    "        for which_qubit in range(N-1):\n",
    "            cir.cnot([which_qubit, which_qubit + 1])\n",
    "        cir.cnot([N-1, 0])\n",
    "\n",
    "    return cir.U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize2unitary(x):\n",
    "    rho_in_mols=x\n",
    "    rho_in_mols=(V@diag(rho_in_mols)@V_H).astype('complex128')\n",
    "    return rho_in_mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_sum(arr, k):\n",
    "    top_k_idx = arr.argsort()[::-1][0:k]\n",
    "    top_k_sum = 0\n",
    "    for idx in top_k_idx:\n",
    "        top_k_sum += arr[idx]\n",
    "    return top_k_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_C = np.diag([1,0]).astype('complex128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(loss, fid):\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(loss, label='train loss', marker=\"s\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.savefig('AE_train_ls1.png')\n",
    "    plt.close()\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"fid\")\n",
    "    plt.plot(fid, label='train fid', marker=\"s\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.savefig('AE_train_fid1.png')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "量子网络搭建\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_A = 2        # 系统 A 的量子比特数\n",
    "N_B = 1        # 系统 B 的量子比特数\n",
    "N = N_A + N_B  # 总的量子比特数\n",
    "# ITR = 100      # 设置迭代次数\n",
    "SEED = 14      # 固定初始化参数用的随机数种子\n",
    "\n",
    "class NET4(fluid.dygraph.Layer):\n",
    "    \"\"\"\n",
    "    Construct the model net\n",
    "    \"\"\"\n",
    "    def __init__(self, shape, param_attr=fluid.initializer.Uniform(\n",
    "        low=0.0, high=2 * np.pi, seed = SEED), dtype='float64'):\n",
    "        super(NET4, self).__init__()\n",
    "        \n",
    "        # 我们需要将 Numpy array 转换成 Paddle 动态图模式中支持的 variable\n",
    "        self.rho_C = fluid.dygraph.to_variable(rho_C)\n",
    "        self.theta = self.create_parameter(shape=shape, \n",
    "                     attr=param_attr, dtype=dtype, is_bias=False)\n",
    "    \n",
    "    # 定义损失函数和前向传播机制\n",
    "    def forward(self,x):\n",
    "        # 生成初始的编码器 E 和解码器 D\\n\",\n",
    "        rho_in= fluid.dygraph.to_variable(x)\n",
    "        E = Encoder(self.theta)\n",
    "        E_dagger = dagger(E)\n",
    "        D = E_dagger\n",
    "        D_dagger = E\n",
    "\n",
    "        # 编码量子态 rho_in\n",
    "        rho_BA = matmul(matmul(E, rho_in), E_dagger)\n",
    "        \n",
    "        # 取 partial_trace() 获得 rho_encode 与 rho_trash\n",
    "        rho_encode = partial_trace(rho_BA, 2 ** N_B, 2 ** N_A, 1)\n",
    "        rho_trash = partial_trace(rho_BA, 2 ** N_B, 2 ** N_A, 2)\n",
    "\n",
    "        # 解码得到量子态 rho_out\n",
    "        rho_CA = kron(self.rho_C, rho_encode)\n",
    "        rho_out = matmul(matmul(D, rho_CA), D_dagger)\n",
    "        \n",
    "        # 通过 rho_trash 计算损失函数\n",
    "        \n",
    "        zero_Hamiltonian = fluid.dygraph.to_variable(np.diag([1,0]).astype('complex128'))\n",
    "        loss = 1 - (trace(matmul(zero_Hamiltonian, rho_trash))).real\n",
    "\n",
    "        return loss, rho_out, rho_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1622/1622 [02:55<00:00,  9.25it/s]\n",
      "epoch: 0 loss: 0.3376 fid: 0.3546\n"
     ]
    }
   ],
   "source": [
    "LR = 0.01       # 设置学习速率\n",
    "EPOCHS = 1\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "    net = NET4([theta_size])\n",
    "\n",
    "    opt = fluid.optimizer.AdagradOptimizer(learning_rate=LR,\n",
    "                          parameter_list=net.parameters())\n",
    "\n",
    "    tr_fid = []\n",
    "    tr_ls = []\n",
    "    best_fid = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_fid = []\n",
    "        epoch_ls = []\n",
    "        for i in tqdm(range(len((new_train)))):\n",
    "            x=new_train[i]\n",
    "            s=top_k_sum(x, 2**N_A)\n",
    "            trainx=normalize2unitary(x)\n",
    "            loss, rho_out, rho_encode=net(trainx)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.minimize(loss)\n",
    "            net.clear_gradients()\n",
    "            fid=state_fidelity(trainx, rho_out.numpy()) / s\n",
    "            epoch_fid.append(fid)\n",
    "            epoch_ls.append(loss.numpy())\n",
    "        tr_fid.append(np.square(np.array(epoch_fid).mean()))\n",
    "        tr_ls.append(np.array(epoch_ls).mean())\n",
    "        \n",
    "        if best_fid < np.square(np.array(epoch_fid).mean()):\n",
    "            best_fid=np.square(np.array(epoch_fid).mean())\n",
    "            fluid.save_dygraph(net.state_dict(), \"autoencoder\")\n",
    "\n",
    "        print('epoch:', epoch, 'loss:', '%.4f' % np.array(epoch_ls).mean(),\n",
    "              'fid:', '%.4f' % np.square(np.array(epoch_fid).mean()))\n",
    "    plot_curve(tr_ls, tr_fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with fluid.dygraph.guard():\n",
    "    ae = NET4([theta_size])\n",
    "    para_state_dict, _ = fluid.load_dygraph(\"autoencoder\")\n",
    "    ae.set_dict(para_state_dict)\n",
    "    x=new_train[1]\n",
    "    s=top_k_sum(x, 2**N_A)\n",
    "    trainx=normalize2unitary(x)\n",
    "    loss, rho_out, rho_encode = ae(trainx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.30623248+0.00000000e+00j,  0.51108471+3.44476226e-01j,\n",
       "        -0.0686515 +3.04685465e-01j, -0.14158599+3.97439879e-01j],\n",
       "       [ 0.51108471-3.44476226e-01j,  0.64130719+2.22044605e-16j,\n",
       "        -0.14150039-2.65052311e-01j,  0.12948984+7.69895264e-01j],\n",
       "       [-0.0686515 -3.04685465e-01j, -0.14150039+2.65052311e-01j,\n",
       "        -0.10876832+0.00000000e+00j, -0.44197562+8.82082120e-02j],\n",
       "       [-0.14158599-3.97439879e-01j,  0.12948984-7.69895264e-01j,\n",
       "        -0.44197562-8.82082120e-02j,  0.77369362+5.55111512e-17j]])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "rho_encode.numpy()"
   ]
  },
  {
   "source": [
    "分类器网络相关\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myRy(theta):\n",
    "    \"\"\"\n",
    "    :param theta: parameter\n",
    "    :return: Y rotation matrix\n",
    "    \"\"\"\n",
    "    return np.array([[np.cos(theta / 2), -np.sin(theta / 2)],\n",
    "                     [np.sin(theta / 2), np.cos(theta / 2)]])\n",
    "\n",
    "def myRz(theta):\n",
    "    \"\"\"\n",
    "    :param theta: parameter\n",
    "    :return: Z rotation matrix\n",
    "    \"\"\"\n",
    "    return np.array([[np.cos(theta / 2) - np.sin(theta / 2) * 1j, 0],\n",
    "                     [0, np.cos(theta / 2) + np.sin(theta / 2) * 1j]])\n",
    "\n",
    "# 经典 -> 量子数据编码器\n",
    "def datapoints_transform_to_state(data, n_qubits):\n",
    "    \"\"\"\n",
    "    :param data: shape [-1, 2]\n",
    "    :param n_qubits: the number of qubits to which the data transformed\n",
    "    :return: shape [-1, 1, 2 ^ n_qubits]\n",
    "    \"\"\"\n",
    "    dim1, dim2 = data.shape\n",
    "    res = []\n",
    "    for sam in range(dim1):\n",
    "        res_state = 1.\n",
    "        zero_state = np.array([[1, 0]])\n",
    "        for i in range(n_qubits):\n",
    "            if i % 2 == 0:\n",
    "                state_tmp=np.dot(zero_state, myRy(np.arcsin(data[sam][0])).T)\n",
    "                state_tmp=np.dot(state_tmp, myRz(np.arccos(data[sam][0] ** 2)).T)\n",
    "                res_state=np.kron(res_state, state_tmp)\n",
    "            elif i % 2 == 1:\n",
    "                state_tmp=np.dot(zero_state, myRy(np.arcsin(data[sam][1])).T)\n",
    "                state_tmp=np.dot(state_tmp, myRz(np.arccos(data[sam][1] ** 2)).T)\n",
    "                res_state=np.kron(res_state, state_tmp)\n",
    "        res.append(res_state)\n",
    "\n",
    "    res = np.array(res)\n",
    "    return res.astype(\"complex128\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_theta(theta, n, depth):  \n",
    "    \"\"\"\n",
    "    :param theta: dim: [n, depth + 3]\n",
    "    :param n: number of qubits\n",
    "    :param depth: circuit depth\n",
    "    :return: U_theta\n",
    "    \"\"\"\n",
    "    # 初始化网络\n",
    "    cir = UAnsatz(n)\n",
    "    \n",
    "    # 先搭建广义的旋转层\n",
    "    for i in range(n):\n",
    "        cir.rz(theta[i][0], i)\n",
    "        cir.ry(theta[i][1], i)\n",
    "        cir.rz(theta[i][2], i)\n",
    "\n",
    "    # 默认深度为 depth = 1\n",
    "    # 搭建纠缠层和 Ry旋转层\n",
    "    for d in range(3, depth + 3):\n",
    "        for i in range(n-1):\n",
    "            cir.cnot([i, i + 1])\n",
    "        cir.cnot([n-1, 0])\n",
    "        for i in range(n):\n",
    "            cir.ry(theta[i][d], i)\n",
    "\n",
    "    return cir.U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Observable(n):\n",
    "    \"\"\"\n",
    "    :param n: number of qubits\n",
    "    :return: local observable: Z \\otimes I \\otimes ...\\otimes I\n",
    "    \"\"\"\n",
    "    Ob = pauli_str_to_matrix([[1.0, 'z0']], n)\n",
    "    return Ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(fluid.dygraph.Layer):\n",
    "    \"\"\"\n",
    "    Construct the model net\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n,      # number of qubits\n",
    "                 depth,  # circuit depth\n",
    "                 seed_paras=1,\n",
    "                 dtype='float64'):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.n = n\n",
    "        self.depth = depth\n",
    "        \n",
    "        # 初始化参数列表 theta，并用 [0, 2*pi] 的均匀分布来填充初始值\n",
    "        self.theta = self.create_parameter(\n",
    "            shape=[n, depth + 3],\n",
    "            attr=fluid.initializer.Uniform(\n",
    "                low=0.0, high=2*PI, seed=seed_paras),\n",
    "            dtype=dtype,\n",
    "            is_bias=False)\n",
    "        \n",
    "        # 初始化偏置 (bias)\n",
    "        self.bias = self.create_parameter(\n",
    "            shape=[1],\n",
    "            attr=fluid.initializer.NormalInitializer(\n",
    "                scale=0.01, seed=seed_paras + 10),\n",
    "            dtype=dtype,\n",
    "            is_bias=False)\n",
    "\n",
    "    # 定义向前传播机制、计算损失函数 和交叉验证正确率\n",
    "    def forward(self, state_in, label):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state_in: The input quantum state, shape [-1, 1, 2^n]\n",
    "            label: label for the input state, shape [-1, 1]\n",
    "        Returns:\n",
    "            The loss:\n",
    "                L = ((<Z> + 1)/2 + bias - label)^2\n",
    "        \"\"\"\n",
    "        #pdb.set_trace()\n",
    "        # 我们需要将 Numpy array 转换成 Paddle 动态图模式中支持的 variable\n",
    "        Ob = fluid.dygraph.to_variable(Observable(self.n))\n",
    "        \n",
    "        label_pp = fluid.dygraph.to_variable(label)\n",
    "        # 按照随机初始化的参数 theta \n",
    "        Utheta = U_theta(self.theta, n=self.n, depth=self.depth)\n",
    "        U_daggerU_dagger = dagger(Utheta)\n",
    "        # 因为 Utheta是学习得到的，我们这里用行向量运算来提速而不会影响训练效果\n",
    "        #state_out = matmul(matmul(state_in, Utheta), U_dagger)  # 维度 [-1, 1, 2 ** n]\n",
    "        state_out = matmul(matmul(state_in, Utheta), U_dagger)\n",
    "        # 测量得到泡利 Z 算符的期望值 <Z>\n",
    "        #E_Z = matmul(matmul(state_out, Ob),\n",
    "                     #transpose(ComplexVariable(state_out.real, -state_out.imag),\n",
    "                               #perm=[0, 2, 1]))\n",
    "        \n",
    "        # 映射 <Z> 处理成标签的估计值 \n",
    "        #state_predict = E_Z.real[:, 0] * 0.5 + 0.5 + self.bias\n",
    "        #loss = fluid.layers.reduce_mean((state_predict - label_pp) ** 2)\n",
    "       \n",
    "        #return loss, state_predict.numpy()\n",
    "        return state_out.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(n=2, depth=3, seed_paras=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "name net_0.w_0, dtype: VarType.FP64 shape: [2, 6] \tlod: {}\n",
       "\tdim: 2, 6\n",
       "\tlayout: NCHW\n",
       "\tdtype: double\n",
       "\tdata: [3.86803 5.91005 3.79571 3.53215 0.796309 4.06779 2.39871 4.53984 5.69638 2.29723 0.596687 2.5571]"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "net.state_dict()['theta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "EnforceNotMet",
     "evalue": "\n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\n2   paddle::platform::DeviceContextPool::Instance()\n3   paddle::operators::FillConstantKernel<double>::Compute(paddle::framework::ExecutionContext const&) const\n4   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 1ul, paddle::operators::FillConstantKernel<float>, paddle::operators::FillConstantKernel<double>, paddle::operators::FillConstantKernel<long>, paddle::operators::FillConstantKernel<int>, paddle::operators::FillConstantKernel<bool>, paddle::operators::FillConstantKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\n5   paddle::imperative::PreparedOp::Run(paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap const&)\n6   paddle::imperative::OpBase::Run(paddle::framework::OperatorBase const&, paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap const&, paddle::platform::Place const&)\n7   paddle::imperative::Tracer::TraceOp(std::string const&, paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap, paddle::platform::Place const&, bool)\n8   paddle::imperative::Tracer::TraceOp(std::string const&, paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap)\n\n----------------------\nError Message Summary:\n----------------------\nError: Need to Create DeviceContextPool first!\n  [Hint: pool should not be null.] at (/paddle/paddle/fluid/platform/device_context.h:456)\n  [operator < fill_constant > error]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEnforceNotMet\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-376b8b5c61b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrainy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#loss, state=net(state_in=input_data,label=trainy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrho_encode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparam_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-fab438a9f527>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state_in, label)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mlabel_pp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdygraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# 按照随机初始化的参数 theta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mUtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU_theta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mU_daggerU_dagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# 因为 Utheta是学习得到的，我们这里用行向量运算来提速而不会影响训练效果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-e75386b8af31>\u001b[0m in \u001b[0;36mU_theta\u001b[0;34m(theta, n, depth)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mcir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work_dir/quantum/paddle_quantum/circuit.py\u001b[0m in \u001b[0;36mU\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m             [ 0.70710678+0.j  0.        +0.j -0.70710678+0.j  0.        +0.j]]\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComplexVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mnum_ele\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/layers/tensor.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, force_cpu)\u001b[0m\n\u001b[1;32m   1085\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 'zeros')\n\u001b[0;32m-> 1087\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfill_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddle/lib/python3.6/site-packages/paddle/fluid/layers/tensor.py\u001b[0m in \u001b[0;36mfill_constant\u001b[0;34m(shape, dtype, value, force_cpu, out)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'force_cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                                \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'str_value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'str_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                                'shape', shape)\n\u001b[0m\u001b[1;32m    716\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEnforceNotMet\u001b[0m: \n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::string paddle::platform::GetTraceBackString<std::string const&>(std::string const&, char const*, int)\n1   paddle::platform::EnforceNotMet::EnforceNotMet(std::string const&, char const*, int)\n2   paddle::platform::DeviceContextPool::Instance()\n3   paddle::operators::FillConstantKernel<double>::Compute(paddle::framework::ExecutionContext const&) const\n4   std::_Function_handler<void (paddle::framework::ExecutionContext const&), paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 1ul, paddle::operators::FillConstantKernel<float>, paddle::operators::FillConstantKernel<double>, paddle::operators::FillConstantKernel<long>, paddle::operators::FillConstantKernel<int>, paddle::operators::FillConstantKernel<bool>, paddle::operators::FillConstantKernel<paddle::platform::float16> >::operator()(char const*, char const*, int) const::{lambda(paddle::framework::ExecutionContext const&)#1}>::_M_invoke(std::_Any_data const&, paddle::framework::ExecutionContext const&)\n5   paddle::imperative::PreparedOp::Run(paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap const&)\n6   paddle::imperative::OpBase::Run(paddle::framework::OperatorBase const&, paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap const&, paddle::platform::Place const&)\n7   paddle::imperative::Tracer::TraceOp(std::string const&, paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap, paddle::platform::Place const&, bool)\n8   paddle::imperative::Tracer::TraceOp(std::string const&, paddle::imperative::NameVarBaseMap const&, paddle::imperative::NameVarBaseMap const&, paddle::framework::AttributeMap)\n\n----------------------\nError Message Summary:\n----------------------\nError: Need to Create DeviceContextPool first!\n  [Hint: pool should not be null.] at (/paddle/paddle/fluid/platform/device_context.h:456)\n  [operator < fill_constant > error]"
     ]
    }
   ],
   "source": [
    "#这里是想测试一下子分类器的输入是酉矩阵时能不能正常计算，但是报错了\n",
    "with fluid.dygraph.guard():\n",
    "    #inputx = rho_encode.numpy().reshape((-1,4,4))\n",
    "    #print(type(inputx), inputx.shape, inputx.dtype)\n",
    "    #input_data=fluid.dygraph.to_variable(rho_encode)\n",
    "    inputy=(np.arange(1).reshape(-1))  \n",
    "    trainy=np.asarray(inputy).astype('float64')\n",
    "    #loss, state=net(state_in=input_data,label=trainy)\n",
    "    state=net(state_in=rho_encode,label=trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}